{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from imageio import imread\n",
    "import numpy as np\n",
    "import os\n",
    "import math\n",
    "import PIL\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_random=True\n",
    "# Tensor and PIL utils\n",
    "\n",
    "def pil_loader(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        img = PIL.Image.open(f)\n",
    "        return img.convert('RGB')\n",
    "\n",
    "def tensor_resample(tensor, dst_size, mode='bilinear'):\n",
    "    return F.interpolate(tensor, dst_size, mode=mode, align_corners=False)\n",
    "\n",
    "def pil_resize_short_edge_to(pil, trg_size):\n",
    "    short_w = pil.width < pil.height\n",
    "    ar_resized_short = (trg_size / pil.width) if short_w else (trg_size / pil.height)\n",
    "    resized = pil.resize((int(pil.width * ar_resized_short), int(pil.height * ar_resized_short)), PIL.Image.BICUBIC)\n",
    "    return resized\n",
    "\n",
    "def pil_resize_long_edge_to(pil, trg_size):\n",
    "    short_w = pil.width < pil.height\n",
    "    ar_resized_long = (trg_size / pil.height) if short_w else (trg_size / pil.width)\n",
    "    resized = pil.resize((int(pil.width * ar_resized_long), int(pil.height * ar_resized_long)), PIL.Image.BICUBIC)\n",
    "    return resized\n",
    "\n",
    "def np_to_pil(npy):\n",
    "    return PIL.Image.fromarray(npy.astype(np.uint8))\n",
    "\n",
    "def pil_to_np(pil):\n",
    "    return np.array(pil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensor_to_np(tensor, cut_dim_to_3=True):\n",
    "    if len(tensor.shape) == 4:\n",
    "        if cut_dim_to_3:\n",
    "            tensor = tensor[0]\n",
    "        else:\n",
    "            return tensor.data.cpu().numpy().transpose((0, 2, 3, 1))\n",
    "    return tensor.data.cpu().numpy().transpose((1,2,0))\n",
    "\n",
    "def np_to_tensor(npy, space):\n",
    "    if space == 'vgg':\n",
    "        return np_to_tensor_correct(npy)\n",
    "    return (torch.Tensor(npy.astype(np.float64) / 127.5) - 1.0).permute((2,0,1)).unsqueeze(0)\n",
    "\n",
    "def np_to_tensor_correct(npy):\n",
    "    pil = np_to_pil(npy)\n",
    "    transform = transforms.Compose([transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    return transform(pil).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Laplacian Pyramid\n",
    "\n",
    "def laplacian(x):\n",
    "    # x - upsample(downsample(x))\n",
    "    return x - tensor_resample(tensor_resample(x, [x.shape[2] // 2, x.shape[3] // 2]), [x.shape[2], x.shape[3]])\n",
    "\n",
    "def make_laplace_pyramid(x, levels):\n",
    "    pyramid = []\n",
    "    current = x\n",
    "    for i in range(levels):\n",
    "        pyramid.append(laplacian(current))\n",
    "        current = tensor_resample(current, (max(current.shape[2] // 2,1), max(current.shape[3] // 2,1)))\n",
    "    pyramid.append(current)\n",
    "    return pyramid\n",
    "\n",
    "def fold_laplace_pyramid(pyramid):\n",
    "    current = pyramid[-1]\n",
    "    for i in range(len(pyramid)-2, -1, -1): # iterate from len-2 to 0\n",
    "        up_h, up_w = pyramid[i].shape[2], pyramid[i].shape[3]\n",
    "        current = pyramid[i] + tensor_resample(current, (up_h,up_w))\n",
    "    return current"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_indices(feat_content, feat_style_all, r, ri, xx, xy, yx):\n",
    "\n",
    "    indices = None\n",
    "    const = 128**2 # 32k or so\n",
    "\n",
    "    feat_style =  feat_style_all[ri]\n",
    "\n",
    "    for i in range(len(feat_style)):\n",
    "        \n",
    "        feat_cont = feat_content[i]\n",
    "        d = feat_style[i].size(1)\n",
    "        feat_style_st = feat_style[i].view(1,d,-1,1)\n",
    "        big_size = feat_cont.shape[2] * feat_cont.shape[3] # num feaxels\n",
    "\n",
    "        stride_x = int(max(math.floor(math.sqrt(big_size//const)),1))\n",
    "        offset_x = np.random.randint(stride_x)\n",
    "        stride_y = int(max(math.ceil(math.sqrt(big_size//const)),1))\n",
    "        offset_y = np.random.randint(stride_y)\n",
    "        xx_arr, xy_arr = np.meshgrid(np.arange(feat_cont.shape[2])[offset_x::stride_x], np.arange(feat_cont.shape[3])[offset_y::stride_y])\n",
    "\n",
    "        xx_arr = np.expand_dims(xx_arr.flatten(),1)\n",
    "        xy_arr = np.expand_dims(xy_arr.flatten(),1)\n",
    "        xc = np.concatenate([xx_arr,xy_arr], 1)\n",
    "\n",
    "        region_mask = r\n",
    "\n",
    "        try:\n",
    "            xc = xc[region_mask[xy_arr[:,0],xx_arr[:,0]], :]\n",
    "        except:\n",
    "            region_mask = region_mask[:,:]\n",
    "            xc = xc[region_mask[xy_arr[:,0],xx_arr[:,0]], :]\n",
    "        \n",
    "        xx[ri].append(xc[:,0])\n",
    "        xy[ri].append(xc[:,1])\n",
    "\n",
    "        feat_result = np.arange(feat_style_st.size(2)).astype(np.int32)\n",
    "        yx[ri].append(feat_result)\n",
    "\n",
    "def get_feature_indices(xx_dict, xy_dict, yx_dict, ri=0, i=0, cnt=32**2):\n",
    "\n",
    "    xx = xx_dict[ri][i][:cnt]\n",
    "    xy = xy_dict[ri][i][:cnt]\n",
    "    yx = yx_dict[ri][i][:cnt]\n",
    "\n",
    "    return xx, xy, yx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spatial_feature_extract(feat_result, feat_content, xx, xy):\n",
    "\n",
    "    l2, l3 = [], []\n",
    "    device = feat_result[0].device\n",
    "\n",
    "    # for each extracted layer\n",
    "    for i in range(len(feat_result)):\n",
    "        fr = feat_result[i]\n",
    "        fc = feat_content[i]\n",
    "\n",
    "        # hack to detect reduced scale\n",
    "        if i>0 and feat_result[i-1].size(2) > feat_result[i].size(2):\n",
    "            xx = xx/2.0\n",
    "            xy = xy/2.0\n",
    "\n",
    "\n",
    "        # go back to ints and get residual\n",
    "        xxm = np.floor(xx).astype(np.float32)\n",
    "        xxr = xx - xxm\n",
    "\n",
    "        xym = np.floor(xy).astype(np.float32)\n",
    "        xyr = xy - xym\n",
    "\n",
    "        # do bilinear resample\n",
    "        w00 = torch.from_numpy((1.-xxr)*(1.-xyr)).float().view(1, 1, -1, 1).to(device)\n",
    "        w01 = torch.from_numpy((1.-xxr)*xyr).float().view(1, 1, -1, 1).to(device)\n",
    "        w10 = torch.from_numpy(xxr*(1.-xyr)).float().view(1, 1, -1, 1).to(device)\n",
    "        w11 = torch.from_numpy(xxr*xyr).float().view(1, 1, -1, 1).to(device)\n",
    "\n",
    "        xxm = np.clip(xxm.astype(np.int32),0,fr.size(2)-1)\n",
    "        xym = np.clip(xym.astype(np.int32),0,fr.size(3)-1)\n",
    "\n",
    "        s00 = xxm*fr.size(3)+xym\n",
    "        s01 = xxm*fr.size(3)+np.clip(xym+1,0,fr.size(3)-1)\n",
    "        s10 = np.clip(xxm+1,0,fr.size(2)-1)*fr.size(3)+(xym)\n",
    "        s11 = np.clip(xxm+1,0,fr.size(2)-1)*fr.size(3)+np.clip(xym+1,0,fr.size(3)-1)\n",
    "\n",
    "        fr = fr.view(1,fr.size(1),fr.size(2)*fr.size(3),1)\n",
    "        fr = fr[:,:,s00,:].mul_(w00).add_(fr[:,:,s01,:].mul_(w01)).add_(fr[:,:,s10,:].mul_(w10)).add_(fr[:,:,s11,:].mul_(w11))\n",
    "\n",
    "        fc = fc.view(1,fc.size(1),fc.size(2)*fc.size(3),1)\n",
    "        fc = fc[:,:,s00,:].mul_(w00).add_(fc[:,:,s01,:].mul_(w01)).add_(fc[:,:,s10,:].mul_(w10)).add_(fc[:,:,s11,:].mul_(w11))\n",
    "\n",
    "        l2.append(fr)\n",
    "        l3.append(fc)\n",
    "\n",
    "    x_st = torch.cat([li.contiguous() for li in l2],1)\n",
    "    c_st = torch.cat([li.contiguous() for li in l3],1)\n",
    "\n",
    "    xx = torch.from_numpy(xx).view(1,1,x_st.size(2),1).float().to(device)\n",
    "    yy = torch.from_numpy(xy).view(1,1,x_st.size(2),1).float().to(device)\n",
    "    \n",
    "    x_st = torch.cat([x_st,xx,yy],1)\n",
    "    c_st = torch.cat([c_st,xx,yy],1)\n",
    "    return x_st, c_st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rgb_to_yuv(rgb):\n",
    "    C = torch.Tensor([[0.577350,0.577350,0.577350],[-0.577350,0.788675,-0.211325],[-0.577350,-0.211325,0.788675]]).to(rgb.device)\n",
    "    yuv = torch.mm(C,rgb)\n",
    "    return yuv\n",
    "\n",
    "def pairwise_distances_cos(x, y):\n",
    "    x_norm = torch.sqrt((x**2).sum(1).view(-1, 1))\n",
    "    y_t = torch.transpose(y, 0, 1)\n",
    "    y_norm = torch.sqrt((y**2).sum(1).view(1, -1))\n",
    "    dist = 1.-torch.mm(x, y_t)/x_norm/y_norm\n",
    "    return dist\n",
    "\n",
    "def pairwise_distances_sq_l2(x, y):\n",
    "    x_norm = (x**2).sum(1).view(-1, 1)\n",
    "    y_t = torch.transpose(y, 0, 1)\n",
    "    y_norm = (y**2).sum(1).view(1, -1)\n",
    "    dist = x_norm + y_norm - 2.0 * torch.mm(x, y_t)\n",
    "    return torch.clamp(dist, 1e-5, 1e5)/x.size(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mask_from_image(image, ignore_color=[0, 0, 0]):\n",
    "    \"\"\"\n",
    "    Create a mask from an image, where pixels matching the ignore_color are set to 0, and others to 1.\n",
    "\n",
    "    :param image_path: Path to the input image.\n",
    "    :param ignore_color: Color to be ignored, default is black ([0, 0, 0]).\n",
    "    :return: Mask tensor of shape (1, H, W), where 1 indicates important areas and 0 indicates areas to ignore.\n",
    "    \"\"\"\n",
    "\n",
    "    # Check if the image is grayscale or RGB\n",
    "    if len(image.shape) == 2:  # Grayscale image\n",
    "        mask = image != ignore_color[0]\n",
    "    else:  # RGB image\n",
    "        mask = np.all(image != ignore_color, axis=-1)\n",
    "\n",
    "    mask = torch.from_numpy(mask).unsqueeze(0).float()\n",
    "\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_regions(content_path, style_path):\n",
    "    s_regions = imread(style_path).transpose(1,0,2)\n",
    "    c_regions = imread(content_path).transpose(1,0,2)\n",
    "\n",
    "    color_codes,c1 = np.unique(s_regions.reshape(-1, s_regions.shape[2]), axis=0,return_counts=True)\n",
    "\n",
    "    color_codes = color_codes[c1>10000]\n",
    "\n",
    "    c_out = []\n",
    "    s_out = []\n",
    "\n",
    "    for c in color_codes:\n",
    "        c_expand =  np.expand_dims(np.expand_dims(c,0),0)\n",
    "        \n",
    "        s_mask = np.equal(np.sum(s_regions - c_expand,axis=2),0).astype(np.float32)\n",
    "        c_mask = np.equal(np.sum(c_regions - c_expand,axis=2),0).astype(np.float32)\n",
    "\n",
    "        s_out.append(s_mask)\n",
    "        c_out.append(c_mask)\n",
    "\n",
    "    return [c_out,s_out]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distmat(x, y, cos_d=True):\n",
    "    if cos_d:\n",
    "        M = pairwise_distances_cos(x, y)\n",
    "    else:\n",
    "        M = torch.sqrt(pairwise_distances_sq_l2(x, y))\n",
    "    return M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def content_loss(feat_result, feat_content):\n",
    "    d = feat_result.size(1)\n",
    "\n",
    "    X = feat_result.transpose(0,1).contiguous().view(d,-1).transpose(0,1)\n",
    "    Y = feat_content.transpose(0,1).contiguous().view(d,-1).transpose(0,1)\n",
    "\n",
    "    Y = Y[:,:-2]\n",
    "    X = X[:,:-2]\n",
    "    # X = X.t()\n",
    "    # Y = Y.t()\n",
    "\n",
    "    Mx = distmat(X, X)\n",
    "    Mx = Mx#/Mx.sum(0, keepdim=True)\n",
    "\n",
    "    My = distmat(Y, Y)\n",
    "    My = My#/My.sum(0, keepdim=True)\n",
    "\n",
    "    d = torch.abs(Mx-My).mean()# * X.shape[0]\n",
    "    return d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def style_loss(X, Y, cos_d=True):\n",
    "    d = X.shape[1]\n",
    "\n",
    "    if d == 3:\n",
    "        X = rgb_to_yuv(X.transpose(0,1).contiguous().view(d,-1)).transpose(0,1)\n",
    "        Y = rgb_to_yuv(Y.transpose(0,1).contiguous().view(d,-1)).transpose(0,1)\n",
    "    else:\n",
    "        X = X.transpose(0,1).contiguous().view(d,-1).transpose(0,1)\n",
    "        Y = Y.transpose(0,1).contiguous().view(d,-1).transpose(0,1)\n",
    "\n",
    "    # Relaxed EMD\n",
    "    CX_M = distmat(X, Y, cos_d=True)\n",
    "\n",
    "    if d==3: CX_M = CX_M + distmat(X, Y, cos_d=False)\n",
    "\n",
    "    m1, m1_inds = CX_M.min(1)\n",
    "    m2, m2_inds = CX_M.min(0)\n",
    "\n",
    "    remd = torch.max(m1.mean(), m2.mean())\n",
    "\n",
    "    return remd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def moment_loss(X, Y, moments=[1,2]):\n",
    "    loss = 0.\n",
    "    d = X.size(1)\n",
    "    # X = X.squeeze().t()\n",
    "    # Y = Y.squeeze().t()\n",
    "\n",
    "    Xo = X.transpose(0,1).contiguous().view(d,-1).transpose(0,1)\n",
    "    Yo = Y.transpose(0,1).contiguous().view(d,-1).transpose(0,1)\n",
    "\n",
    "    splits = [Xo.size(1)]\n",
    "\n",
    "    cb = 0\n",
    "    ce = 0\n",
    "    for i in range(len(splits)):\n",
    "        ce = cb + splits[i]\n",
    "        X = Xo[:,cb:ce]\n",
    "        Y = Yo[:,cb:ce]\n",
    "        cb = ce\n",
    "\n",
    "        mu_x = torch.mean(X,0,keepdim=True)\n",
    "        mu_y = torch.mean(Y,0,keepdim=True)\n",
    "        mu_d = torch.abs(mu_x-mu_y).mean()\n",
    "\n",
    "        if 1 in moments:\n",
    "            # print(mu_x.shape)\n",
    "            loss = loss + mu_d\n",
    "\n",
    "        if 2 in moments:\n",
    "\n",
    "            sig_x = torch.mm((X-mu_x).transpose(0,1), (X-mu_x))/X.size(0)\n",
    "            sig_y = torch.mm((Y-mu_y).transpose(0,1), (Y-mu_y))/Y.size(0)\n",
    "\n",
    "            sig_d = torch.abs(sig_x-sig_y).mean()\n",
    "\n",
    "            # print(X_cov.shape)\n",
    "            # exit(1)\n",
    "            loss = loss + sig_d\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_loss(feat_result, feat_content, feat_style, xx_dict, xy_dict, yx_dict, content_weight, regions, moment_weight=1.0):\n",
    "    # spatial feature extract\n",
    "    num_locations = 1024\n",
    "    loss_total = 0.\n",
    "\n",
    "    for ri in range(len(regions[0])):\n",
    "        xx, xy, yx = get_feature_indices(xx_dict, xy_dict, yx_dict, ri=ri, cnt=num_locations)\n",
    "        spatial_result, spatial_content = spatial_feature_extract(feat_result, feat_content, xx, xy)\n",
    "\n",
    "        loss_content = content_loss(spatial_result, spatial_content)\n",
    "\n",
    "        d = feat_style[ri][0].shape[0]\n",
    "        spatial_style = feat_style[ri][0].view(1, d, -1, 1)\n",
    "\n",
    "        feat_max = 3+2*64+128*2+256*3+512*2 # (sum of all extracted channels)\n",
    "\n",
    "        loss_remd = style_loss(spatial_result[:, :feat_max, :, :], spatial_style[:, :feat_max, :, :])\n",
    "\n",
    "        loss_moment = moment_loss(spatial_result[:,:-2,:,:], spatial_style, moments=[1,2]) # -2 is so that it can fit?\n",
    "        # palette matching\n",
    "        content_weight_frac = 1./max(content_weight,1.)\n",
    "        loss_moment += content_weight_frac * style_loss(spatial_result[:,:3,:,:], spatial_style[:,:3,:,:])\n",
    "        \n",
    "        loss_style = loss_remd + moment_weight * loss_moment\n",
    "        print(f'Style: {loss_style.item():.3f}, Content: {loss_content.item():.3f}')\n",
    "\n",
    "        style_weight = 1.0 + moment_weight\n",
    "        loss_total += (content_weight * loss_content + loss_style) / (content_weight + style_weight)\n",
    "\n",
    "    return loss_total/len(xx_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESAMPLE_FREQ = 1\n",
    "\n",
    "class Vgg16_Extractor(nn.Module):\n",
    "    def __init__(self, space):\n",
    "        super().__init__()\n",
    "        self.vgg_layers = models.vgg16(pretrained=True).features\n",
    "\n",
    "        for param in self.parameters():\n",
    "            param.requires_grad = False\n",
    "        self.capture_layers = [1,3,6,8,11,13,15,22,29]\n",
    "        self.space = space\n",
    "        \n",
    "    def forward_base(self, x):\n",
    "        feat = [x]\n",
    "        for i in range(len(self.vgg_layers)):\n",
    "            x = self.vgg_layers[i](x)\n",
    "            if i in self.capture_layers: feat.append(x)\n",
    "        return feat\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.space != 'vgg':\n",
    "            x = (x + 1.) / 2.\n",
    "            x = x - (torch.Tensor([0.485, 0.456, 0.406]).to(x.device).view(1, -1, 1, 1))\n",
    "            x = x / (torch.Tensor([0.229, 0.224, 0.225]).to(x.device).view(1, -1, 1, 1))\n",
    "        feat = self.forward_base(x)\n",
    "        return feat\n",
    "    \n",
    "    def forward_samples_hypercolumn(self, X, samps=100):\n",
    "        feat = self.forward(X)\n",
    "\n",
    "        xx,xy = np.meshgrid(np.arange(X.shape[2]), np.arange(X.shape[3]))\n",
    "        xx = np.expand_dims(xx.flatten(),1)\n",
    "        xy = np.expand_dims(xy.flatten(),1)\n",
    "        xc = np.concatenate([xx,xy],1)\n",
    "        \n",
    "        samples = min(samps,xc.shape[0])\n",
    "\n",
    "        np.random.shuffle(xc)\n",
    "        xx = xc[:samples,0]\n",
    "        yy = xc[:samples,1]\n",
    "\n",
    "        feat_samples = []\n",
    "        for i in range(len(feat)):\n",
    "\n",
    "            layer_feat = feat[i]\n",
    "\n",
    "            # hack to detect lower resolution\n",
    "            if i>0 and feat[i].size(2) < feat[i-1].size(2):\n",
    "                xx = xx/2.0\n",
    "                yy = yy/2.0\n",
    "\n",
    "            xx = np.clip(xx, 0, layer_feat.shape[2]-1).astype(np.int32)\n",
    "            yy = np.clip(yy, 0, layer_feat.shape[3]-1).astype(np.int32)\n",
    "\n",
    "            features = layer_feat[:,:, xx[range(samples)], yy[range(samples)]]\n",
    "            feat_samples.append(features.clone().detach())\n",
    "\n",
    "        feat = torch.cat(feat_samples,1)\n",
    "        return feat\n",
    "    \n",
    "    def forward_cat(self, X, r, samps=100):\n",
    "        feat = self.forward(X)\n",
    "\n",
    "        try:\n",
    "            r = r[:,:,0]\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        if r.max()<0.1:\n",
    "            region_mask = np.greater(r.flatten()+1.,0.5)\n",
    "        else:\n",
    "            region_mask = np.greater(r.flatten(),0.5)\n",
    "\n",
    "        xx,xy = np.meshgrid(np.arange(X.shape[2]), np.arange(X.shape[3]))\n",
    "        xx = np.expand_dims(xx.flatten(),1)\n",
    "        xy = np.expand_dims(xy.flatten(),1)\n",
    "        xc = np.concatenate([xx,xy],1)\n",
    "\n",
    "        xc = xc[region_mask,:]\n",
    "\n",
    "        samples = min(samps,xc.shape[0])\n",
    "\n",
    "        np.random.shuffle(xc)\n",
    "        xx = xc[:samples,0]\n",
    "        yy = xc[:samples,1]\n",
    "\n",
    "        feat_samples = []\n",
    "        for i in range(len(feat)):\n",
    "            layer_feat = feat[i]\n",
    "            # hack to detect lower resolution\n",
    "            if i>0 and feat[i].size(2) < feat[i-1].size(2):\n",
    "                xx = xx/2.0\n",
    "                yy = yy/2.0\n",
    "            \n",
    "            xx = np.clip(xx, 0, layer_feat.shape[2]-1).astype(np.int32)\n",
    "            yy = np.clip(yy, 0, layer_feat.shape[3]-1).astype(np.int32)\n",
    "\n",
    "            features = layer_feat[:,:, xx[range(samples)], yy[range(samples)]]\n",
    "            feat_samples.append(features.clone().detach())\n",
    "\n",
    "        feat = torch.cat(feat_samples,1)\n",
    "        return feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize(result, content, style, content_path, style_path, scale, content_weight, lr, extractor, regions=0):\n",
    "    # torch.autograd.set_detect_anomaly(True)\n",
    "    result_pyramid = make_laplace_pyramid(result, 5)\n",
    "    result_pyramid = [l.data.requires_grad_() for l in result_pyramid]\n",
    "\n",
    "    opt_iter = 200\n",
    "\n",
    "    # use rmsprop\n",
    "    optimizer = optim.RMSprop(result_pyramid, lr=lr)\n",
    "\n",
    "    # extract features for content\n",
    "    feat_content = extractor(content) # \n",
    "\n",
    "    stylized = fold_laplace_pyramid(result_pyramid)\n",
    "    \n",
    "    # some inner loop that extracts samples\n",
    "    feat_style_all = []\n",
    "    for ri in range(len(regions[0])):\n",
    "        r_temp = regions[0][ri]\n",
    "        if len(r_temp.shape) > 2:\n",
    "            r_temp = r_temp[:,:,0]\n",
    "        \n",
    "        r_temp = torch.from_numpy(r_temp).unsqueeze(0).unsqueeze(0).contiguous()\n",
    "        r = tensor_resample(r_temp,[style.size(3),style.size(2)])[0,0,:,:].numpy()\n",
    "        feat_style = None\n",
    "        for j in range(5):\n",
    "            with torch.no_grad():\n",
    "                feat_e = extractor.forward_cat(style, r, samps=1000)  \n",
    "                feat_style = feat_e if feat_style is None else torch.cat((feat_style, feat_e), dim=2)\n",
    "        feat_style_all.append(feat_style)\n",
    "\n",
    "    xx = {}\n",
    "    xy = {}\n",
    "    yx = {}\n",
    "        \n",
    "    for ri in range(len(regions[0])):\n",
    "\n",
    "        try:\n",
    "            temp = xx[ri]\n",
    "        except:\n",
    "            xx[ri] = []\n",
    "            xy[ri] = []\n",
    "            yx[ri] = []\n",
    "\n",
    "        r_temp = regions[0][ri]\n",
    "        r_temp = torch.from_numpy(r_temp).unsqueeze(0).unsqueeze(0).contiguous()\n",
    "        r = tensor_resample(r_temp, ([stylized.size(3), stylized.size(2)]))[0,0,:,:].numpy()     \n",
    "\n",
    "        if r.max()<0.1:\n",
    "            r = np.greater(r+1.,0.5)\n",
    "        else:\n",
    "            r = np.greater(r,0.5)\n",
    "   \n",
    "        sample_indices(feat_content, feat_style_all, r, ri, xx, xy, yx) # 0 to sample over first layer extracted\n",
    "\n",
    "    # init indices to optimize over\n",
    "    # xx, xy = sample_indices(feat_content[0], feat_style) # 0 to sample over first layer extracted\n",
    "    for it in range(opt_iter):\n",
    "        optimizer.zero_grad()\n",
    "        stylized = fold_laplace_pyramid(result_pyramid)\n",
    "        # original code has resample here, seems pointless with uniform shuffle\n",
    "        # ...\n",
    "        # also shuffle them every y iter\n",
    "        if it % 1 == 0 and it != 0:\n",
    "            for ri in xx.keys():\n",
    "                np.random.shuffle(xx[ri][0])\n",
    "                np.random.shuffle(xy[ri][0])\n",
    "                np.random.shuffle(yx[ri][0])\n",
    "\n",
    "        feat_result = extractor(stylized)\n",
    "\n",
    "        loss = calculate_loss(feat_result, feat_content, feat_style_all, xx, xy, yx, content_weight, regions)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    return stylized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strotss(content_pil, style_pil, content_path, style_path, regions, content_weight=1.0*16.0, device='cuda:0', space='uniform', content_mask=None, style_mask=None):\n",
    "    content_np = pil_to_np(content_pil)\n",
    "    style_np = pil_to_np(style_pil)\n",
    "    content_full = np_to_tensor(content_np, space).to(device)\n",
    "    style_full = np_to_tensor(style_np, space).to(device)\n",
    "\n",
    "    if content_mask is not None and style_mask is not None:\n",
    "        content_mask = content_mask.to(device)\n",
    "        style_mask = style_mask.to(device)\n",
    "\n",
    "    lr = 2e-3\n",
    "    extractor = Vgg16_Extractor(space=space).to(device)\n",
    "\n",
    "    scale_last = max(content_full.shape[2], content_full.shape[3])\n",
    "    scales = []\n",
    "    for scale in range(10):\n",
    "        divisor = 2**scale\n",
    "        if min(content_pil.width, content_pil.height) // divisor >= 33:\n",
    "            scales.insert(0, divisor)\n",
    "    \n",
    "    for scale in scales:\n",
    "        # rescale content to current scale\n",
    "        content = tensor_resample(content_full, [ content_full.shape[2] // scale, content_full.shape[3] // scale ])\n",
    "        style = tensor_resample(style_full, [ style_full.shape[2] // scale, style_full.shape[3] // scale ])\n",
    "        print(f'Optimizing at resoluton [{content.shape[2]}, {content.shape[3]}]')\n",
    "\n",
    "        # upsample or initialize the result\n",
    "        if scale == scales[0]:\n",
    "            # first\n",
    "            result = laplacian(content) + style.mean(2,keepdim=True).mean(3,keepdim=True)\n",
    "        elif scale == scales[-1]:\n",
    "            # last \n",
    "            result = tensor_resample(result, [content.shape[2], content.shape[3]])\n",
    "            lr = 1e-3\n",
    "        else:\n",
    "            result = tensor_resample(result, [content.shape[2], content.shape[3]]) + laplacian(content)\n",
    "\n",
    "        # do the optimization on this scale\n",
    "        result = optimize(result, content, style, content_path, style_path, scale, content_weight=content_weight, lr=lr, extractor=extractor, regions=regions)\n",
    "\n",
    "        # next scale lower weight\n",
    "        content_weight /= 2.0\n",
    "\n",
    "    clow = -1.0 if space == 'uniform' else -1.7\n",
    "    chigh = 1.0 if space == 'uniform' else 1.7\n",
    "    result_image = tensor_to_np(tensor_resample(torch.clamp(result, clow, chigh), [content_full.shape[2], content_full.shape[3]])) # \n",
    "    # renormalize image\n",
    "    result_image -= result_image.min()\n",
    "    result_image /= result_image.max()\n",
    "    return np_to_pil(result_image * 255.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xiongjiangkai/.virtualenvs/.Data_science/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/xiongjiangkai/.virtualenvs/.Data_science/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing at resoluton [48, 64]\n",
      "Style: 1.668, Content: 0.089\n",
      "Style: 1.468, Content: 0.062\n",
      "Style: 1.442, Content: 0.042\n",
      "Style: 1.395, Content: 0.037\n",
      "Style: 1.382, Content: 0.033\n",
      "Style: 1.342, Content: 0.035\n",
      "Style: 1.368, Content: 0.029\n",
      "Style: 1.322, Content: 0.031\n",
      "Style: 1.328, Content: 0.028\n",
      "Style: 1.315, Content: 0.029\n",
      "Style: 1.310, Content: 0.027\n",
      "Style: 1.302, Content: 0.028\n",
      "Style: 1.280, Content: 0.027\n",
      "Style: 1.316, Content: 0.026\n",
      "Style: 1.250, Content: 0.029\n",
      "Style: 1.322, Content: 0.025\n",
      "Style: 1.251, Content: 0.028\n",
      "Style: 1.285, Content: 0.024\n",
      "Style: 1.235, Content: 0.025\n",
      "Style: 1.264, Content: 0.023\n",
      "Style: 1.243, Content: 0.024\n",
      "Style: 1.243, Content: 0.023\n",
      "Style: 1.225, Content: 0.024\n",
      "Style: 1.232, Content: 0.024\n",
      "Style: 1.223, Content: 0.024\n",
      "Style: 1.221, Content: 0.023\n",
      "Style: 1.230, Content: 0.023\n",
      "Style: 1.218, Content: 0.023\n",
      "Style: 1.228, Content: 0.022\n",
      "Style: 1.195, Content: 0.024\n",
      "Style: 1.212, Content: 0.022\n",
      "Style: 1.216, Content: 0.023\n",
      "Style: 1.207, Content: 0.022\n",
      "Style: 1.208, Content: 0.023\n",
      "Style: 1.211, Content: 0.022\n",
      "Style: 1.191, Content: 0.022\n",
      "Style: 1.199, Content: 0.023\n",
      "Style: 1.187, Content: 0.022\n",
      "Style: 1.193, Content: 0.022\n",
      "Style: 1.197, Content: 0.021\n",
      "Style: 1.183, Content: 0.022\n",
      "Style: 1.198, Content: 0.021\n",
      "Style: 1.185, Content: 0.021\n",
      "Style: 1.191, Content: 0.021\n",
      "Style: 1.189, Content: 0.021\n",
      "Style: 1.196, Content: 0.021\n",
      "Style: 1.187, Content: 0.022\n",
      "Style: 1.192, Content: 0.021\n",
      "Style: 1.171, Content: 0.022\n",
      "Style: 1.187, Content: 0.020\n",
      "Style: 1.162, Content: 0.022\n",
      "Style: 1.199, Content: 0.020\n",
      "Style: 1.178, Content: 0.022\n",
      "Style: 1.180, Content: 0.021\n",
      "Style: 1.158, Content: 0.021\n",
      "Style: 1.188, Content: 0.020\n",
      "Style: 1.183, Content: 0.021\n",
      "Style: 1.175, Content: 0.020\n",
      "Style: 1.151, Content: 0.020\n",
      "Style: 1.179, Content: 0.019\n",
      "Style: 1.149, Content: 0.020\n",
      "Style: 1.169, Content: 0.020\n",
      "Style: 1.163, Content: 0.020\n",
      "Style: 1.170, Content: 0.020\n",
      "Style: 1.175, Content: 0.020\n",
      "Style: 1.180, Content: 0.020\n",
      "Style: 1.149, Content: 0.020\n",
      "Style: 1.172, Content: 0.019\n",
      "Style: 1.147, Content: 0.020\n",
      "Style: 1.177, Content: 0.020\n",
      "Style: 1.151, Content: 0.020\n",
      "Style: 1.188, Content: 0.020\n",
      "Style: 1.139, Content: 0.021\n",
      "Style: 1.143, Content: 0.019\n",
      "Style: 1.135, Content: 0.020\n",
      "Style: 1.156, Content: 0.019\n",
      "Style: 1.148, Content: 0.021\n",
      "Style: 1.178, Content: 0.019\n",
      "Style: 1.140, Content: 0.021\n",
      "Style: 1.160, Content: 0.019\n",
      "Style: 1.140, Content: 0.020\n",
      "Style: 1.171, Content: 0.019\n",
      "Style: 1.153, Content: 0.019\n",
      "Style: 1.148, Content: 0.019\n",
      "Style: 1.136, Content: 0.019\n",
      "Style: 1.151, Content: 0.019\n",
      "Style: 1.154, Content: 0.019\n",
      "Style: 1.153, Content: 0.019\n",
      "Style: 1.154, Content: 0.019\n",
      "Style: 1.146, Content: 0.018\n",
      "Style: 1.144, Content: 0.020\n",
      "Style: 1.170, Content: 0.018\n",
      "Style: 1.122, Content: 0.020\n",
      "Style: 1.164, Content: 0.018\n",
      "Style: 1.137, Content: 0.020\n",
      "Style: 1.172, Content: 0.018\n",
      "Style: 1.131, Content: 0.020\n",
      "Style: 1.162, Content: 0.019\n",
      "Style: 1.152, Content: 0.020\n",
      "Style: 1.162, Content: 0.018\n",
      "Style: 1.134, Content: 0.019\n",
      "Style: 1.136, Content: 0.018\n",
      "Style: 1.128, Content: 0.019\n",
      "Style: 1.147, Content: 0.018\n",
      "Style: 1.126, Content: 0.019\n",
      "Style: 1.144, Content: 0.018\n",
      "Style: 1.126, Content: 0.019\n",
      "Style: 1.154, Content: 0.018\n",
      "Style: 1.132, Content: 0.019\n",
      "Style: 1.132, Content: 0.018\n",
      "Style: 1.126, Content: 0.019\n",
      "Style: 1.169, Content: 0.018\n",
      "Style: 1.127, Content: 0.019\n",
      "Style: 1.145, Content: 0.018\n",
      "Style: 1.138, Content: 0.019\n",
      "Style: 1.148, Content: 0.018\n",
      "Style: 1.138, Content: 0.019\n",
      "Style: 1.142, Content: 0.019\n",
      "Style: 1.128, Content: 0.018\n",
      "Style: 1.144, Content: 0.018\n",
      "Style: 1.138, Content: 0.018\n",
      "Style: 1.119, Content: 0.018\n",
      "Style: 1.140, Content: 0.018\n",
      "Style: 1.137, Content: 0.018\n",
      "Style: 1.142, Content: 0.017\n",
      "Style: 1.120, Content: 0.019\n",
      "Style: 1.138, Content: 0.018\n",
      "Style: 1.121, Content: 0.019\n",
      "Style: 1.142, Content: 0.018\n",
      "Style: 1.117, Content: 0.019\n",
      "Style: 1.144, Content: 0.018\n",
      "Style: 1.119, Content: 0.019\n",
      "Style: 1.159, Content: 0.018\n",
      "Style: 1.131, Content: 0.018\n",
      "Style: 1.140, Content: 0.018\n",
      "Style: 1.124, Content: 0.019\n",
      "Style: 1.152, Content: 0.017\n",
      "Style: 1.117, Content: 0.019\n",
      "Style: 1.131, Content: 0.018\n",
      "Style: 1.122, Content: 0.018\n",
      "Style: 1.133, Content: 0.018\n",
      "Style: 1.139, Content: 0.018\n",
      "Style: 1.124, Content: 0.018\n",
      "Style: 1.116, Content: 0.019\n",
      "Style: 1.144, Content: 0.018\n",
      "Style: 1.113, Content: 0.019\n",
      "Style: 1.136, Content: 0.018\n",
      "Style: 1.123, Content: 0.018\n",
      "Style: 1.137, Content: 0.018\n",
      "Style: 1.130, Content: 0.018\n",
      "Style: 1.126, Content: 0.018\n",
      "Style: 1.095, Content: 0.018\n",
      "Style: 1.117, Content: 0.017\n",
      "Style: 1.126, Content: 0.017\n",
      "Style: 1.117, Content: 0.018\n",
      "Style: 1.131, Content: 0.017\n",
      "Style: 1.113, Content: 0.018\n",
      "Style: 1.140, Content: 0.018\n",
      "Style: 1.085, Content: 0.019\n",
      "Style: 1.123, Content: 0.017\n",
      "Style: 1.104, Content: 0.019\n",
      "Style: 1.147, Content: 0.017\n",
      "Style: 1.108, Content: 0.019\n",
      "Style: 1.135, Content: 0.017\n",
      "Style: 1.105, Content: 0.018\n",
      "Style: 1.129, Content: 0.017\n",
      "Style: 1.101, Content: 0.018\n",
      "Style: 1.112, Content: 0.018\n",
      "Style: 1.106, Content: 0.018\n",
      "Style: 1.125, Content: 0.017\n",
      "Style: 1.082, Content: 0.018\n",
      "Style: 1.121, Content: 0.018\n",
      "Style: 1.106, Content: 0.018\n",
      "Style: 1.093, Content: 0.017\n",
      "Style: 1.110, Content: 0.018\n",
      "Style: 1.124, Content: 0.017\n",
      "Style: 1.096, Content: 0.018\n",
      "Style: 1.119, Content: 0.017\n",
      "Style: 1.108, Content: 0.018\n",
      "Style: 1.115, Content: 0.017\n",
      "Style: 1.100, Content: 0.018\n",
      "Style: 1.127, Content: 0.017\n",
      "Style: 1.116, Content: 0.017\n",
      "Style: 1.113, Content: 0.017\n",
      "Style: 1.122, Content: 0.017\n",
      "Style: 1.100, Content: 0.017\n",
      "Style: 1.118, Content: 0.018\n",
      "Style: 1.135, Content: 0.017\n",
      "Style: 1.088, Content: 0.019\n",
      "Style: 1.111, Content: 0.018\n",
      "Style: 1.113, Content: 0.018\n",
      "Style: 1.118, Content: 0.017\n",
      "Style: 1.115, Content: 0.018\n",
      "Style: 1.110, Content: 0.017\n",
      "Style: 1.108, Content: 0.018\n",
      "Style: 1.113, Content: 0.017\n",
      "Style: 1.106, Content: 0.018\n",
      "Style: 1.116, Content: 0.017\n",
      "Style: 1.095, Content: 0.019\n",
      "Style: 1.144, Content: 0.017\n",
      "Optimizing at resoluton [96, 128]\n",
      "Style: 1.372, Content: 0.058\n",
      "Style: 1.151, Content: 0.074\n",
      "Style: 1.072, Content: 0.058\n",
      "Style: 1.038, Content: 0.052\n",
      "Style: 1.064, Content: 0.045\n",
      "Style: 1.014, Content: 0.047\n",
      "Style: 1.014, Content: 0.042\n",
      "Style: 0.975, Content: 0.043\n",
      "Style: 0.995, Content: 0.041\n",
      "Style: 0.968, Content: 0.041\n",
      "Style: 0.980, Content: 0.038\n",
      "Style: 0.953, Content: 0.041\n",
      "Style: 0.984, Content: 0.036\n",
      "Style: 0.949, Content: 0.042\n",
      "Style: 0.970, Content: 0.036\n",
      "Style: 0.934, Content: 0.040\n",
      "Style: 0.942, Content: 0.037\n",
      "Style: 0.911, Content: 0.039\n",
      "Style: 0.920, Content: 0.035\n",
      "Style: 0.907, Content: 0.039\n",
      "Style: 0.937, Content: 0.036\n",
      "Style: 0.919, Content: 0.038\n",
      "Style: 0.922, Content: 0.035\n",
      "Style: 0.902, Content: 0.039\n",
      "Style: 0.929, Content: 0.035\n",
      "Style: 0.901, Content: 0.038\n",
      "Style: 0.926, Content: 0.036\n",
      "Style: 0.905, Content: 0.037\n",
      "Style: 0.916, Content: 0.037\n",
      "Style: 0.910, Content: 0.037\n",
      "Style: 0.913, Content: 0.035\n",
      "Style: 0.879, Content: 0.037\n",
      "Style: 0.899, Content: 0.036\n",
      "Style: 0.875, Content: 0.037\n",
      "Style: 0.903, Content: 0.035\n",
      "Style: 0.883, Content: 0.036\n",
      "Style: 0.890, Content: 0.036\n",
      "Style: 0.887, Content: 0.036\n",
      "Style: 0.869, Content: 0.037\n",
      "Style: 0.891, Content: 0.034\n",
      "Style: 0.886, Content: 0.037\n",
      "Style: 0.902, Content: 0.034\n",
      "Style: 0.868, Content: 0.036\n",
      "Style: 0.881, Content: 0.034\n",
      "Style: 0.870, Content: 0.036\n",
      "Style: 0.882, Content: 0.034\n",
      "Style: 0.866, Content: 0.037\n",
      "Style: 0.868, Content: 0.034\n",
      "Style: 0.877, Content: 0.035\n",
      "Style: 0.879, Content: 0.035\n",
      "Style: 0.879, Content: 0.034\n",
      "Style: 0.882, Content: 0.035\n",
      "Style: 0.856, Content: 0.035\n",
      "Style: 0.877, Content: 0.034\n",
      "Style: 0.864, Content: 0.036\n",
      "Style: 0.870, Content: 0.034\n",
      "Style: 0.856, Content: 0.036\n",
      "Style: 0.867, Content: 0.034\n",
      "Style: 0.862, Content: 0.035\n",
      "Style: 0.883, Content: 0.033\n",
      "Style: 0.870, Content: 0.035\n",
      "Style: 0.867, Content: 0.034\n",
      "Style: 0.861, Content: 0.034\n",
      "Style: 0.869, Content: 0.035\n",
      "Style: 0.863, Content: 0.034\n",
      "Style: 0.847, Content: 0.035\n",
      "Style: 0.855, Content: 0.034\n",
      "Style: 0.849, Content: 0.035\n",
      "Style: 0.861, Content: 0.034\n",
      "Style: 0.859, Content: 0.035\n",
      "Style: 0.851, Content: 0.034\n",
      "Style: 0.855, Content: 0.035\n",
      "Style: 0.854, Content: 0.034\n",
      "Style: 0.872, Content: 0.035\n",
      "Style: 0.852, Content: 0.035\n",
      "Style: 0.835, Content: 0.034\n",
      "Style: 0.859, Content: 0.034\n",
      "Style: 0.845, Content: 0.035\n",
      "Style: 0.862, Content: 0.033\n",
      "Style: 0.840, Content: 0.035\n",
      "Style: 0.874, Content: 0.033\n",
      "Style: 0.838, Content: 0.035\n",
      "Style: 0.868, Content: 0.034\n",
      "Style: 0.853, Content: 0.034\n",
      "Style: 0.867, Content: 0.033\n",
      "Style: 0.859, Content: 0.035\n",
      "Style: 0.848, Content: 0.034\n",
      "Style: 0.844, Content: 0.034\n",
      "Style: 0.841, Content: 0.033\n",
      "Style: 0.829, Content: 0.035\n",
      "Style: 0.849, Content: 0.033\n",
      "Style: 0.860, Content: 0.034\n",
      "Style: 0.862, Content: 0.033\n",
      "Style: 0.844, Content: 0.034\n",
      "Style: 0.859, Content: 0.033\n",
      "Style: 0.840, Content: 0.035\n",
      "Style: 0.835, Content: 0.034\n",
      "Style: 0.869, Content: 0.033\n",
      "Style: 0.838, Content: 0.034\n",
      "Style: 0.861, Content: 0.034\n",
      "Style: 0.825, Content: 0.035\n",
      "Style: 0.858, Content: 0.032\n",
      "Style: 0.846, Content: 0.034\n",
      "Style: 0.857, Content: 0.032\n",
      "Style: 0.827, Content: 0.035\n",
      "Style: 0.869, Content: 0.032\n",
      "Style: 0.838, Content: 0.035\n",
      "Style: 0.834, Content: 0.034\n",
      "Style: 0.837, Content: 0.035\n",
      "Style: 0.838, Content: 0.033\n",
      "Style: 0.824, Content: 0.035\n",
      "Style: 0.846, Content: 0.033\n",
      "Style: 0.850, Content: 0.034\n",
      "Style: 0.833, Content: 0.034\n",
      "Style: 0.836, Content: 0.035\n",
      "Style: 0.837, Content: 0.033\n",
      "Style: 0.836, Content: 0.034\n",
      "Style: 0.828, Content: 0.034\n",
      "Style: 0.820, Content: 0.034\n",
      "Style: 0.841, Content: 0.033\n",
      "Style: 0.832, Content: 0.035\n",
      "Style: 0.835, Content: 0.033\n",
      "Style: 0.840, Content: 0.034\n",
      "Style: 0.834, Content: 0.033\n",
      "Style: 0.847, Content: 0.034\n",
      "Style: 0.827, Content: 0.034\n",
      "Style: 0.838, Content: 0.034\n",
      "Style: 0.825, Content: 0.034\n",
      "Style: 0.836, Content: 0.033\n",
      "Style: 0.830, Content: 0.034\n",
      "Style: 0.849, Content: 0.034\n",
      "Style: 0.827, Content: 0.034\n",
      "Style: 0.825, Content: 0.033\n",
      "Style: 0.830, Content: 0.034\n",
      "Style: 0.832, Content: 0.034\n",
      "Style: 0.823, Content: 0.034\n",
      "Style: 0.841, Content: 0.033\n",
      "Style: 0.826, Content: 0.034\n",
      "Style: 0.832, Content: 0.034\n",
      "Style: 0.826, Content: 0.035\n",
      "Style: 0.834, Content: 0.034\n",
      "Style: 0.831, Content: 0.034\n",
      "Style: 0.836, Content: 0.033\n",
      "Style: 0.823, Content: 0.034\n",
      "Style: 0.828, Content: 0.033\n",
      "Style: 0.822, Content: 0.034\n",
      "Style: 0.839, Content: 0.033\n",
      "Style: 0.844, Content: 0.034\n",
      "Style: 0.836, Content: 0.033\n",
      "Style: 0.815, Content: 0.036\n",
      "Style: 0.832, Content: 0.033\n",
      "Style: 0.825, Content: 0.034\n",
      "Style: 0.826, Content: 0.034\n",
      "Style: 0.816, Content: 0.034\n",
      "Style: 0.828, Content: 0.033\n",
      "Style: 0.828, Content: 0.033\n",
      "Style: 0.842, Content: 0.033\n",
      "Style: 0.805, Content: 0.035\n",
      "Style: 0.832, Content: 0.033\n",
      "Style: 0.823, Content: 0.034\n",
      "Style: 0.847, Content: 0.033\n",
      "Style: 0.818, Content: 0.034\n",
      "Style: 0.819, Content: 0.033\n",
      "Style: 0.819, Content: 0.033\n",
      "Style: 0.830, Content: 0.033\n",
      "Style: 0.833, Content: 0.034\n",
      "Style: 0.832, Content: 0.033\n",
      "Style: 0.827, Content: 0.034\n",
      "Style: 0.820, Content: 0.033\n",
      "Style: 0.824, Content: 0.033\n",
      "Style: 0.825, Content: 0.033\n",
      "Style: 0.824, Content: 0.034\n",
      "Style: 0.825, Content: 0.033\n",
      "Style: 0.815, Content: 0.034\n",
      "Style: 0.834, Content: 0.032\n",
      "Style: 0.812, Content: 0.035\n",
      "Style: 0.835, Content: 0.033\n",
      "Style: 0.811, Content: 0.034\n",
      "Style: 0.848, Content: 0.032\n",
      "Style: 0.818, Content: 0.034\n",
      "Style: 0.821, Content: 0.034\n",
      "Style: 0.816, Content: 0.033\n",
      "Style: 0.822, Content: 0.033\n",
      "Style: 0.820, Content: 0.034\n",
      "Style: 0.826, Content: 0.033\n",
      "Style: 0.812, Content: 0.034\n",
      "Style: 0.832, Content: 0.033\n",
      "Style: 0.823, Content: 0.033\n",
      "Style: 0.822, Content: 0.034\n",
      "Style: 0.825, Content: 0.033\n",
      "Style: 0.822, Content: 0.033\n",
      "Style: 0.817, Content: 0.034\n",
      "Style: 0.831, Content: 0.032\n",
      "Style: 0.841, Content: 0.033\n",
      "Style: 0.815, Content: 0.034\n",
      "Style: 0.812, Content: 0.034\n",
      "Style: 0.844, Content: 0.033\n",
      "Style: 0.836, Content: 0.033\n",
      "Style: 0.824, Content: 0.032\n",
      "Style: 0.821, Content: 0.034\n",
      "Optimizing at resoluton [192, 256]\n",
      "Style: 1.391, Content: 0.056\n",
      "Style: 1.099, Content: 0.068\n",
      "Style: 0.940, Content: 0.074\n",
      "Style: 0.888, Content: 0.060\n",
      "Style: 0.864, Content: 0.061\n",
      "Style: 0.834, Content: 0.057\n",
      "Style: 0.817, Content: 0.059\n",
      "Style: 0.819, Content: 0.054\n",
      "Style: 0.813, Content: 0.056\n",
      "Style: 0.788, Content: 0.056\n",
      "Style: 0.783, Content: 0.054\n",
      "Style: 0.761, Content: 0.053\n",
      "Style: 0.764, Content: 0.054\n",
      "Style: 0.752, Content: 0.054\n",
      "Style: 0.751, Content: 0.054\n",
      "Style: 0.740, Content: 0.052\n",
      "Style: 0.753, Content: 0.053\n",
      "Style: 0.731, Content: 0.055\n",
      "Style: 0.735, Content: 0.053\n",
      "Style: 0.731, Content: 0.052\n",
      "Style: 0.733, Content: 0.053\n",
      "Style: 0.732, Content: 0.052\n",
      "Style: 0.728, Content: 0.052\n",
      "Style: 0.718, Content: 0.054\n",
      "Style: 0.718, Content: 0.052\n",
      "Style: 0.726, Content: 0.052\n",
      "Style: 0.716, Content: 0.053\n",
      "Style: 0.712, Content: 0.052\n",
      "Style: 0.705, Content: 0.052\n",
      "Style: 0.697, Content: 0.052\n",
      "Style: 0.725, Content: 0.051\n",
      "Style: 0.699, Content: 0.054\n",
      "Style: 0.718, Content: 0.052\n",
      "Style: 0.694, Content: 0.054\n",
      "Style: 0.704, Content: 0.050\n",
      "Style: 0.701, Content: 0.051\n",
      "Style: 0.717, Content: 0.050\n",
      "Style: 0.700, Content: 0.051\n",
      "Style: 0.707, Content: 0.051\n",
      "Style: 0.693, Content: 0.052\n",
      "Style: 0.687, Content: 0.053\n",
      "Style: 0.692, Content: 0.052\n",
      "Style: 0.701, Content: 0.051\n",
      "Style: 0.690, Content: 0.051\n",
      "Style: 0.700, Content: 0.051\n",
      "Style: 0.676, Content: 0.052\n",
      "Style: 0.697, Content: 0.050\n",
      "Style: 0.695, Content: 0.051\n",
      "Style: 0.677, Content: 0.051\n",
      "Style: 0.693, Content: 0.050\n",
      "Style: 0.686, Content: 0.051\n",
      "Style: 0.683, Content: 0.051\n",
      "Style: 0.682, Content: 0.051\n",
      "Style: 0.687, Content: 0.051\n",
      "Style: 0.686, Content: 0.051\n",
      "Style: 0.669, Content: 0.052\n",
      "Style: 0.699, Content: 0.050\n",
      "Style: 0.675, Content: 0.052\n",
      "Style: 0.684, Content: 0.050\n",
      "Style: 0.674, Content: 0.052\n",
      "Style: 0.697, Content: 0.051\n",
      "Style: 0.677, Content: 0.051\n",
      "Style: 0.676, Content: 0.051\n",
      "Style: 0.673, Content: 0.051\n",
      "Style: 0.678, Content: 0.051\n",
      "Style: 0.688, Content: 0.050\n",
      "Style: 0.682, Content: 0.051\n",
      "Style: 0.661, Content: 0.053\n",
      "Style: 0.679, Content: 0.050\n",
      "Style: 0.666, Content: 0.051\n",
      "Style: 0.669, Content: 0.051\n",
      "Style: 0.675, Content: 0.050\n",
      "Style: 0.670, Content: 0.051\n",
      "Style: 0.674, Content: 0.050\n",
      "Style: 0.669, Content: 0.051\n",
      "Style: 0.681, Content: 0.049\n",
      "Style: 0.662, Content: 0.052\n",
      "Style: 0.670, Content: 0.051\n",
      "Style: 0.671, Content: 0.049\n",
      "Style: 0.688, Content: 0.049\n",
      "Style: 0.669, Content: 0.052\n",
      "Style: 0.673, Content: 0.051\n",
      "Style: 0.667, Content: 0.051\n",
      "Style: 0.668, Content: 0.049\n",
      "Style: 0.672, Content: 0.051\n",
      "Style: 0.672, Content: 0.049\n",
      "Style: 0.672, Content: 0.051\n",
      "Style: 0.677, Content: 0.049\n",
      "Style: 0.666, Content: 0.051\n",
      "Style: 0.669, Content: 0.050\n",
      "Style: 0.669, Content: 0.051\n",
      "Style: 0.676, Content: 0.049\n",
      "Style: 0.677, Content: 0.049\n",
      "Style: 0.668, Content: 0.051\n",
      "Style: 0.669, Content: 0.050\n",
      "Style: 0.658, Content: 0.050\n",
      "Style: 0.667, Content: 0.049\n",
      "Style: 0.668, Content: 0.050\n",
      "Style: 0.663, Content: 0.050\n",
      "Style: 0.658, Content: 0.050\n",
      "Style: 0.658, Content: 0.050\n",
      "Style: 0.660, Content: 0.049\n",
      "Style: 0.662, Content: 0.051\n",
      "Style: 0.661, Content: 0.050\n",
      "Style: 0.671, Content: 0.048\n",
      "Style: 0.663, Content: 0.049\n",
      "Style: 0.666, Content: 0.049\n",
      "Style: 0.675, Content: 0.050\n",
      "Style: 0.665, Content: 0.049\n",
      "Style: 0.652, Content: 0.050\n",
      "Style: 0.659, Content: 0.049\n",
      "Style: 0.666, Content: 0.050\n",
      "Style: 0.668, Content: 0.050\n",
      "Style: 0.659, Content: 0.050\n",
      "Style: 0.656, Content: 0.049\n",
      "Style: 0.656, Content: 0.050\n",
      "Style: 0.661, Content: 0.049\n",
      "Style: 0.662, Content: 0.050\n",
      "Style: 0.669, Content: 0.049\n",
      "Style: 0.664, Content: 0.049\n",
      "Style: 0.663, Content: 0.049\n",
      "Style: 0.655, Content: 0.051\n",
      "Style: 0.668, Content: 0.049\n",
      "Style: 0.659, Content: 0.049\n",
      "Style: 0.659, Content: 0.049\n",
      "Style: 0.660, Content: 0.049\n",
      "Style: 0.650, Content: 0.050\n",
      "Style: 0.657, Content: 0.050\n",
      "Style: 0.658, Content: 0.050\n",
      "Style: 0.656, Content: 0.050\n",
      "Style: 0.644, Content: 0.051\n",
      "Style: 0.656, Content: 0.050\n",
      "Style: 0.654, Content: 0.050\n",
      "Style: 0.655, Content: 0.049\n",
      "Style: 0.668, Content: 0.049\n",
      "Style: 0.644, Content: 0.051\n",
      "Style: 0.665, Content: 0.049\n",
      "Style: 0.644, Content: 0.049\n",
      "Style: 0.651, Content: 0.049\n",
      "Style: 0.653, Content: 0.049\n",
      "Style: 0.653, Content: 0.048\n",
      "Style: 0.643, Content: 0.052\n",
      "Style: 0.651, Content: 0.049\n",
      "Style: 0.653, Content: 0.050\n",
      "Style: 0.655, Content: 0.050\n",
      "Style: 0.652, Content: 0.050\n",
      "Style: 0.659, Content: 0.048\n",
      "Style: 0.648, Content: 0.050\n",
      "Style: 0.674, Content: 0.049\n",
      "Style: 0.650, Content: 0.049\n",
      "Style: 0.646, Content: 0.051\n",
      "Style: 0.641, Content: 0.050\n",
      "Style: 0.653, Content: 0.050\n",
      "Style: 0.652, Content: 0.050\n",
      "Style: 0.656, Content: 0.049\n",
      "Style: 0.656, Content: 0.048\n",
      "Style: 0.645, Content: 0.051\n",
      "Style: 0.659, Content: 0.050\n",
      "Style: 0.649, Content: 0.049\n",
      "Style: 0.659, Content: 0.049\n",
      "Style: 0.660, Content: 0.048\n",
      "Style: 0.644, Content: 0.051\n",
      "Style: 0.662, Content: 0.049\n",
      "Style: 0.653, Content: 0.049\n",
      "Style: 0.643, Content: 0.050\n",
      "Style: 0.643, Content: 0.050\n",
      "Style: 0.660, Content: 0.051\n",
      "Style: 0.652, Content: 0.051\n",
      "Style: 0.653, Content: 0.050\n",
      "Style: 0.650, Content: 0.050\n",
      "Style: 0.638, Content: 0.050\n",
      "Style: 0.643, Content: 0.049\n",
      "Style: 0.656, Content: 0.049\n",
      "Style: 0.645, Content: 0.049\n",
      "Style: 0.659, Content: 0.048\n",
      "Style: 0.643, Content: 0.050\n",
      "Style: 0.647, Content: 0.049\n",
      "Style: 0.644, Content: 0.050\n",
      "Style: 0.652, Content: 0.048\n",
      "Style: 0.652, Content: 0.048\n",
      "Style: 0.644, Content: 0.050\n",
      "Style: 0.645, Content: 0.050\n",
      "Style: 0.650, Content: 0.049\n",
      "Style: 0.638, Content: 0.049\n",
      "Style: 0.657, Content: 0.048\n",
      "Style: 0.636, Content: 0.051\n",
      "Style: 0.640, Content: 0.049\n",
      "Style: 0.642, Content: 0.049\n",
      "Style: 0.642, Content: 0.049\n",
      "Style: 0.645, Content: 0.051\n",
      "Style: 0.651, Content: 0.049\n",
      "Style: 0.643, Content: 0.050\n",
      "Style: 0.642, Content: 0.050\n",
      "Style: 0.649, Content: 0.048\n",
      "Style: 0.638, Content: 0.050\n",
      "Style: 0.650, Content: 0.048\n",
      "Style: 0.647, Content: 0.050\n",
      "Style: 0.638, Content: 0.048\n",
      "Style: 0.654, Content: 0.047\n",
      "Style: 0.637, Content: 0.050\n",
      "Optimizing at resoluton [384, 512]\n",
      "Style: 1.214, Content: 0.073\n",
      "Style: 1.042, Content: 0.082\n",
      "Style: 0.959, Content: 0.080\n",
      "Style: 0.911, Content: 0.077\n",
      "Style: 0.889, Content: 0.079\n",
      "Style: 0.866, Content: 0.076\n",
      "Style: 0.843, Content: 0.076\n",
      "Style: 0.827, Content: 0.077\n",
      "Style: 0.817, Content: 0.075\n",
      "Style: 0.804, Content: 0.072\n",
      "Style: 0.791, Content: 0.073\n",
      "Style: 0.779, Content: 0.072\n",
      "Style: 0.771, Content: 0.074\n",
      "Style: 0.762, Content: 0.073\n",
      "Style: 0.755, Content: 0.073\n",
      "Style: 0.760, Content: 0.072\n",
      "Style: 0.750, Content: 0.072\n",
      "Style: 0.740, Content: 0.073\n",
      "Style: 0.743, Content: 0.072\n",
      "Style: 0.736, Content: 0.072\n",
      "Style: 0.720, Content: 0.072\n",
      "Style: 0.731, Content: 0.071\n",
      "Style: 0.725, Content: 0.071\n",
      "Style: 0.722, Content: 0.072\n",
      "Style: 0.716, Content: 0.071\n",
      "Style: 0.717, Content: 0.071\n",
      "Style: 0.714, Content: 0.071\n",
      "Style: 0.718, Content: 0.070\n",
      "Style: 0.721, Content: 0.071\n",
      "Style: 0.702, Content: 0.070\n",
      "Style: 0.709, Content: 0.071\n",
      "Style: 0.707, Content: 0.070\n",
      "Style: 0.694, Content: 0.071\n",
      "Style: 0.697, Content: 0.069\n",
      "Style: 0.706, Content: 0.071\n",
      "Style: 0.699, Content: 0.069\n",
      "Style: 0.695, Content: 0.068\n",
      "Style: 0.694, Content: 0.069\n",
      "Style: 0.690, Content: 0.069\n",
      "Style: 0.686, Content: 0.069\n",
      "Style: 0.679, Content: 0.069\n",
      "Style: 0.685, Content: 0.071\n",
      "Style: 0.680, Content: 0.069\n",
      "Style: 0.674, Content: 0.070\n",
      "Style: 0.685, Content: 0.069\n",
      "Style: 0.675, Content: 0.070\n",
      "Style: 0.675, Content: 0.070\n",
      "Style: 0.676, Content: 0.069\n",
      "Style: 0.690, Content: 0.070\n",
      "Style: 0.674, Content: 0.069\n",
      "Style: 0.679, Content: 0.069\n",
      "Style: 0.681, Content: 0.070\n",
      "Style: 0.674, Content: 0.069\n",
      "Style: 0.683, Content: 0.070\n",
      "Style: 0.674, Content: 0.069\n",
      "Style: 0.670, Content: 0.070\n",
      "Style: 0.672, Content: 0.070\n",
      "Style: 0.668, Content: 0.069\n",
      "Style: 0.669, Content: 0.069\n",
      "Style: 0.662, Content: 0.070\n",
      "Style: 0.665, Content: 0.070\n",
      "Style: 0.660, Content: 0.069\n",
      "Style: 0.669, Content: 0.069\n",
      "Style: 0.660, Content: 0.069\n",
      "Style: 0.656, Content: 0.069\n",
      "Style: 0.661, Content: 0.070\n",
      "Style: 0.661, Content: 0.070\n",
      "Style: 0.660, Content: 0.068\n",
      "Style: 0.657, Content: 0.069\n",
      "Style: 0.653, Content: 0.069\n",
      "Style: 0.654, Content: 0.069\n",
      "Style: 0.655, Content: 0.068\n",
      "Style: 0.649, Content: 0.068\n",
      "Style: 0.644, Content: 0.069\n",
      "Style: 0.648, Content: 0.069\n",
      "Style: 0.651, Content: 0.070\n",
      "Style: 0.654, Content: 0.068\n",
      "Style: 0.648, Content: 0.069\n",
      "Style: 0.648, Content: 0.070\n",
      "Style: 0.645, Content: 0.069\n",
      "Style: 0.648, Content: 0.070\n",
      "Style: 0.652, Content: 0.070\n",
      "Style: 0.648, Content: 0.069\n",
      "Style: 0.644, Content: 0.070\n",
      "Style: 0.646, Content: 0.069\n",
      "Style: 0.642, Content: 0.070\n",
      "Style: 0.645, Content: 0.070\n",
      "Style: 0.641, Content: 0.069\n",
      "Style: 0.646, Content: 0.069\n",
      "Style: 0.643, Content: 0.069\n",
      "Style: 0.646, Content: 0.069\n",
      "Style: 0.630, Content: 0.070\n",
      "Style: 0.651, Content: 0.069\n",
      "Style: 0.636, Content: 0.069\n",
      "Style: 0.641, Content: 0.071\n",
      "Style: 0.650, Content: 0.069\n",
      "Style: 0.639, Content: 0.069\n",
      "Style: 0.636, Content: 0.069\n",
      "Style: 0.633, Content: 0.068\n",
      "Style: 0.631, Content: 0.070\n",
      "Style: 0.637, Content: 0.069\n",
      "Style: 0.633, Content: 0.070\n",
      "Style: 0.634, Content: 0.069\n",
      "Style: 0.637, Content: 0.069\n",
      "Style: 0.634, Content: 0.069\n",
      "Style: 0.637, Content: 0.069\n",
      "Style: 0.635, Content: 0.068\n",
      "Style: 0.632, Content: 0.067\n",
      "Style: 0.641, Content: 0.068\n",
      "Style: 0.630, Content: 0.070\n",
      "Style: 0.634, Content: 0.068\n",
      "Style: 0.637, Content: 0.068\n",
      "Style: 0.629, Content: 0.069\n",
      "Style: 0.641, Content: 0.069\n",
      "Style: 0.628, Content: 0.068\n",
      "Style: 0.630, Content: 0.069\n",
      "Style: 0.628, Content: 0.070\n",
      "Style: 0.623, Content: 0.070\n",
      "Style: 0.629, Content: 0.070\n",
      "Style: 0.631, Content: 0.070\n",
      "Style: 0.628, Content: 0.069\n",
      "Style: 0.630, Content: 0.067\n",
      "Style: 0.628, Content: 0.069\n",
      "Style: 0.621, Content: 0.070\n",
      "Style: 0.625, Content: 0.068\n",
      "Style: 0.627, Content: 0.068\n",
      "Style: 0.625, Content: 0.070\n",
      "Style: 0.621, Content: 0.068\n",
      "Style: 0.637, Content: 0.068\n",
      "Style: 0.628, Content: 0.070\n",
      "Style: 0.624, Content: 0.069\n",
      "Style: 0.626, Content: 0.069\n",
      "Style: 0.625, Content: 0.070\n",
      "Style: 0.628, Content: 0.069\n",
      "Style: 0.628, Content: 0.069\n",
      "Style: 0.630, Content: 0.070\n",
      "Style: 0.623, Content: 0.068\n",
      "Style: 0.623, Content: 0.068\n",
      "Style: 0.616, Content: 0.069\n",
      "Style: 0.625, Content: 0.069\n",
      "Style: 0.617, Content: 0.069\n",
      "Style: 0.617, Content: 0.069\n",
      "Style: 0.622, Content: 0.069\n",
      "Style: 0.622, Content: 0.069\n",
      "Style: 0.631, Content: 0.068\n",
      "Style: 0.618, Content: 0.070\n",
      "Style: 0.618, Content: 0.070\n",
      "Style: 0.621, Content: 0.071\n",
      "Style: 0.629, Content: 0.070\n",
      "Style: 0.617, Content: 0.070\n",
      "Style: 0.623, Content: 0.068\n",
      "Style: 0.617, Content: 0.068\n",
      "Style: 0.610, Content: 0.069\n",
      "Style: 0.620, Content: 0.068\n",
      "Style: 0.622, Content: 0.069\n",
      "Style: 0.617, Content: 0.069\n",
      "Style: 0.615, Content: 0.068\n",
      "Style: 0.618, Content: 0.069\n",
      "Style: 0.615, Content: 0.069\n",
      "Style: 0.622, Content: 0.068\n",
      "Style: 0.620, Content: 0.068\n",
      "Style: 0.616, Content: 0.069\n",
      "Style: 0.617, Content: 0.069\n",
      "Style: 0.614, Content: 0.069\n",
      "Style: 0.617, Content: 0.071\n",
      "Style: 0.617, Content: 0.068\n",
      "Style: 0.618, Content: 0.068\n",
      "Style: 0.612, Content: 0.069\n",
      "Style: 0.620, Content: 0.069\n",
      "Style: 0.620, Content: 0.068\n",
      "Style: 0.615, Content: 0.069\n",
      "Style: 0.619, Content: 0.068\n",
      "Style: 0.619, Content: 0.070\n",
      "Style: 0.621, Content: 0.067\n",
      "Style: 0.617, Content: 0.068\n",
      "Style: 0.611, Content: 0.069\n",
      "Style: 0.614, Content: 0.069\n",
      "Style: 0.618, Content: 0.068\n",
      "Style: 0.618, Content: 0.068\n",
      "Style: 0.614, Content: 0.070\n",
      "Style: 0.614, Content: 0.070\n",
      "Style: 0.615, Content: 0.068\n",
      "Style: 0.611, Content: 0.068\n",
      "Style: 0.614, Content: 0.069\n",
      "Style: 0.613, Content: 0.069\n",
      "Style: 0.610, Content: 0.068\n",
      "Style: 0.614, Content: 0.069\n",
      "Style: 0.614, Content: 0.067\n",
      "Style: 0.620, Content: 0.068\n",
      "Style: 0.616, Content: 0.066\n",
      "Style: 0.608, Content: 0.067\n",
      "Style: 0.617, Content: 0.070\n",
      "Style: 0.614, Content: 0.069\n",
      "Style: 0.607, Content: 0.068\n",
      "Style: 0.612, Content: 0.070\n",
      "Style: 0.611, Content: 0.069\n",
      "Style: 0.618, Content: 0.069\n",
      "Style: 0.610, Content: 0.069\n",
      "Style: 0.606, Content: 0.069\n",
      "Style: 0.610, Content: 0.068\n",
      "Done in 141.625s\n"
     ]
    }
   ],
   "source": [
    "args={\"content\": \"content.jpg\", \"style\": \"style.jpg\", \"content_mask\": None, \"style_mask\": None, \"weight\": 1.0, \"output\": \"strotss.png\", \"device\": \"cuda:0\", \"ospace\": \"uniform\", \"resize_to\": 512}\n",
    "args[\"content\"] =\"/Users/xiongjiangkai/Downloads/cv_heol/test_content/Tuebingen_Neckarfront.jpg\"\n",
    "args[\"style\"] = \"/Users/xiongjiangkai/Downloads/cv_heol/test_style/vangogh_starry_night.jpg\"\n",
    "args[\"output\"]=args[\"content\"].split('/')[-1].split('.')[0]+\"_\"+args[\"style\"].split('/')[-1].split('.')[0]+\".png\"\n",
    "\n",
    "# make 256 the smallest possible long side, will still fail if short side is <\n",
    "if args[\"resize_to\"] < 2**8:\n",
    "    print(\"Resulution too low.\")\n",
    "    exit(1)\n",
    "\n",
    "content_pil, style_pil = pil_loader(args[\"content\"]), pil_loader(args[\"style\"])\n",
    "content_mask, style_mask = None, None\n",
    "\n",
    "if args[\"content_mask\"] and args[\"style_mask\"] is not None:\n",
    "    regions = extract_regions(args[\"content_mask\"], args[\"style_mask\"])\n",
    "\n",
    "    pil_content_mask = pil_loader(args[\"content_mask\"])\n",
    "    pil_style_mask = pil_loader(args[\"style_mask\"])\n",
    "\n",
    "    pil_content_mask = pil_resize_long_edge_to(pil_content_mask, args[\"resize_to\"])\n",
    "    pil_style_mask = pil_resize_long_edge_to(pil_style_mask, args[\"resize_to\"])\n",
    "\n",
    "    content_mask = pil_to_np(pil_content_mask)\n",
    "    style_mask = pil_to_np(pil_style_mask)\n",
    "\n",
    "    content_mask = create_mask_from_image(content_mask)\n",
    "    style_mask = create_mask_from_image(style_mask)\n",
    "else:\n",
    "    try:\n",
    "        regions = [[pil_to_np(pil_resize_long_edge_to(pil_loader(args[\"content\"]), args[\"resize_to\"]))[:,:,0]*0.+1.], [pil_to_np(pil_resize_long_edge_to(pil_loader(args[\"style\"]), args[\"resize_to\"]))[:,:,0]*0.+1.]]\n",
    "    except:\n",
    "        regions = [[pil_to_np(pil_resize_long_edge_to(pil_loader(args[\"content\"]), args[\"resize_to\"]))[:,:]*0.+1.], [pil_to_np(pil_resize_long_edge_to(pil_loader(args[\"style\"]), args[\"resize_to\"]))[:,:]*0.+1.]]\n",
    "\n",
    "content_weight = args[\"weight\"] * 16.0\n",
    "\n",
    "device = \"mps\"\n",
    "\n",
    "start = time()\n",
    "result = strotss(pil_resize_long_edge_to(content_pil, args[\"resize_to\"]), \n",
    "                    pil_resize_long_edge_to(style_pil, args[\"resize_to\"]), args[\"content\"], args[\"style\"], regions, content_weight, device, args[\"ospace\"], content_mask=content_mask, style_mask=style_mask)\n",
    "result.save(args[\"output\"])\n",
    "print(f'Done in {time()-start:.3f}s')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".Data_science",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
