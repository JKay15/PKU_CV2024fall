{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207265ae-1f97-41aa-b9fc-6549826c855a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os \n",
    "content_dir = os.getcwd() + 'img/content/'\n",
    "style_dir = os.getcwd() + 'img/style/'\n",
    "model_dir = os.getcwd() + '/Models/'\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "\n",
    "from PIL import Image\n",
    "from collections import OrderedDict\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "93bdd469-6c51-4e24-9673-e70103769011",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class VGG(nn.Module):\n",
    "#     def __init__(self, pool='max'):\n",
    "#         super(VGG, self).__init__()\n",
    "#         # vgg modules\n",
    "#         self.features = nn.Sequential(\n",
    "#             nn.Conv2d(3, 64, kernel_size=3, padding=1),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "#             nn.ReLU(),\n",
    "#             nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "#             nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
    "#             nn.ReLU(),\n",
    "#             nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "#             nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "#             nn.ReLU(),\n",
    "#             nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "#             nn.Conv2d(256, 512, kernel_size=3, padding=1),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "#             nn.ReLU(),\n",
    "#             nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "#             nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "#             nn.ReLU(),\n",
    "#             nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "#         )\n",
    "#         self.classifier = nn.Sequential(\n",
    "#             nn.Linear(512 * 7 * 7, 4096),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Dropout(),\n",
    "#             nn.Linear(4096, 4096),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Dropout(),\n",
    "#             nn.Linear(4096, 1000)\n",
    "#         )\n",
    "\n",
    "#     def forward(self, x, out_keys):\n",
    "#         out = {}\n",
    "#         out['r11'] = self.features[1](self.features[0](x))\n",
    "#         out['r12'] = self.features[3](self.features[2](out['r11']))\n",
    "#         out['p1'] = self.features[4](out['r12'])\n",
    "#         out['r21'] = self.features[6](self.features[5](out['p1']))\n",
    "#         out['r22'] = self.features[8](self.features[7](out['r21']))\n",
    "#         out['p2'] = self.features[9](out['r22'])\n",
    "#         out['r31'] = self.features[11](self.features[10](out['p2']))\n",
    "#         out['r32'] = self.features[13](self.features[12](out['r31']))\n",
    "#         out['r33'] = self.features[15](self.features[14](out['r32']))\n",
    "#         out['r34'] = self.features[17](self.features[16](out['r33']))\n",
    "#         out['p3'] = self.features[18](out['r34'])\n",
    "#         out['r41'] = self.features[20](self.features[19](out['p3']))\n",
    "#         out['r42'] = self.features[22](self.features[21](out['r41']))\n",
    "#         out['r43'] = self.features[24](self.features[23](out['r42']))\n",
    "#         out['r44'] = self.features[26](self.features[25](out['r43']))\n",
    "#         out['p4'] = self.features[27](out['r44'])\n",
    "#         out['r51'] = self.features[28](self.features[27](out['p4']))\n",
    "#         out['r52'] = self.features[30](self.features[29](out['r51']))\n",
    "#         out['r53'] = self.features[32](self.features[31](out['r52']))\n",
    "#         out['r54'] = self.features[34](self.features[33](out['r53']))\n",
    "#         out['p5'] = self.features[35](out['r54'])\n",
    "#         return [out[key] for key in out_keys]\n",
    "class VGG(nn.Module):\n",
    "    def __init__(self, pool='max'):\n",
    "        super(VGG, self).__init__()\n",
    "        #vgg modules\n",
    "        self.conv1_1 = nn.Conv2d(3, 64, kernel_size=3, padding=1)\n",
    "        self.conv1_2 = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
    "        self.conv2_1 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.conv2_2 = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
    "        self.conv3_1 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
    "        self.conv3_2 = nn.Conv2d(256, 256, kernel_size=3, padding=1)\n",
    "        self.conv3_3 = nn.Conv2d(256, 256, kernel_size=3, padding=1)\n",
    "        self.conv3_4 = nn.Conv2d(256, 256, kernel_size=3, padding=1)\n",
    "        self.conv4_1 = nn.Conv2d(256, 512, kernel_size=3, padding=1)\n",
    "        self.conv4_2 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
    "        self.conv4_3 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
    "        self.conv4_4 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
    "        self.conv5_1 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
    "        self.conv5_2 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
    "        self.conv5_3 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
    "        self.conv5_4 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
    "        if pool == 'max':\n",
    "            self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "            self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "            self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "            self.pool4 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "            self.pool5 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        elif pool == 'avg':\n",
    "            self.pool1 = nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "            self.pool2 = nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "            self.pool3 = nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "            self.pool4 = nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "            self.pool5 = nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "            \n",
    "    def forward(self, x, out_keys):\n",
    "        out = {}\n",
    "        out['r11'] = F.relu(self.conv1_1(x))\n",
    "        out['r12'] = F.relu(self.conv1_2(out['r11']))\n",
    "        out['p1'] = self.pool1(out['r12'])\n",
    "        out['r21'] = F.relu(self.conv2_1(out['p1']))\n",
    "        out['r22'] = F.relu(self.conv2_2(out['r21']))\n",
    "        out['p2'] = self.pool2(out['r22'])\n",
    "        out['r31'] = F.relu(self.conv3_1(out['p2']))\n",
    "        out['r32'] = F.relu(self.conv3_2(out['r31']))\n",
    "        out['r33'] = F.relu(self.conv3_3(out['r32']))\n",
    "        out['r34'] = F.relu(self.conv3_4(out['r33']))\n",
    "        out['p3'] = self.pool3(out['r34'])\n",
    "        out['r41'] = F.relu(self.conv4_1(out['p3']))\n",
    "        out['r42'] = F.relu(self.conv4_2(out['r41']))\n",
    "        out['r43'] = F.relu(self.conv4_3(out['r42']))\n",
    "        out['r44'] = F.relu(self.conv4_4(out['r43']))\n",
    "        out['p4'] = self.pool4(out['r44'])\n",
    "        out['r51'] = F.relu(self.conv5_1(out['p4']))\n",
    "        out['r52'] = F.relu(self.conv5_2(out['r51']))\n",
    "        out['r53'] = F.relu(self.conv5_3(out['r52']))\n",
    "        out['r54'] = F.relu(self.conv5_4(out['r53']))\n",
    "        out['p5'] = self.pool5(out['r54'])\n",
    "        return [out[key] for key in out_keys]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6ad6d5aa-30e4-4327-b934-5d5aea9025a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gram matrix and loss\n",
    "class GramMatrix(nn.Module):\n",
    "    def forward(self, input):\n",
    "        b,c,h,w = input.size()\n",
    "        F = input.view(b, c, h*w)\n",
    "        G = torch.bmm(F, F.transpose(1,2)) \n",
    "        G.div_(h*w)\n",
    "        return G\n",
    "\n",
    "class GramMSELoss(nn.Module):\n",
    "    def forward(self, input, target):\n",
    "        out = nn.MSELoss()(GramMatrix()(input), target)\n",
    "        return(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8ea7a36c-b0aa-43ae-864e-55285d73e33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LaplacianNetwork(nn.Module):\n",
    "    def __init__(self, in_channels=3):\n",
    "        super(LaplacianNetwork, self).__init__()\n",
    "        # pooling layer\n",
    "        self.pooling_layer = nn.AvgPool2d(kernel_size=4, stride=4)\n",
    "        # laplacian filter\n",
    "        laplacian_filter = torch.Tensor([[0, -1, 0],\n",
    "                                         [-1, 4, -1],\n",
    "                                         [0, -1, 0]])\n",
    "        laplacian_filter = laplacian_filter.view(1, 1, 3, 3).repeat(1, in_channels, 1, 1)\n",
    "        self.laplacian_filter = nn.Conv2d(in_channels, 1, kernel_size=3, padding=1, bias=False)\n",
    "        self.laplacian_filter.weight = nn.Parameter(laplacian_filter)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pooling_layer(x)\n",
    "        x = self.laplacian_filter(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "579d4321-dd9a-494b-8c39-64c94ea744a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre and post processing for images\n",
    "img_size = 512 \n",
    "prep = transforms.Compose([transforms.Resize(img_size),\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Lambda(lambda x: x[torch.LongTensor([2,1,0])]), #turn to BGR\n",
    "                           transforms.Normalize(mean=[0.40760392, 0.45795686, 0.48501961], #subtract imagenet mean\n",
    "                                                std=[1,1,1]),\n",
    "                           transforms.Lambda(lambda x: x.mul_(255)),\n",
    "                          ])\n",
    "postpa = transforms.Compose([transforms.Lambda(lambda x: x.mul_(1./255)),\n",
    "                           transforms.Normalize(mean=[-0.40760392, -0.45795686, -0.48501961], #add imagenet mean\n",
    "                                                std=[1,1,1]),\n",
    "                           transforms.Lambda(lambda x: x[torch.LongTensor([2,1,0])]), #turn to RGB\n",
    "                           ])\n",
    "postpb = transforms.Compose([transforms.ToPILImage()])\n",
    "def postp(tensor): # to clip results in the range [0,1]\n",
    "    t = postpa(tensor)\n",
    "    t[t>1] = 1    \n",
    "    t[t<0] = 0\n",
    "    img = postpb(t)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2259fdc-5a94-4e38-8a3a-eb22a0315255",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get network\n",
    "vgg = VGG()\n",
    "vgg.load_state_dict(torch.load(model_dir + 'vgg_conv_2014.pth'))\n",
    "#from torchvision import transforms, models\n",
    "#vgg = models.vgg19(pretrained=True)\n",
    "for param in vgg.parameters():\n",
    "    param.requires_grad = False\n",
    "if torch.cuda.is_available():\n",
    "    vgg.cuda()\n",
    "\n",
    "lap = LaplacianNetwork()\n",
    "for param in lap.parameters():\n",
    "    param.requires_grad = False\n",
    "if torch.cuda.is_available():\n",
    "    lap.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94fea0c2-3b5c-49ef-95d1-eb13782ba0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load images, ordered as [style_image, content_image]\n",
    "img_dirs = [style_dir,content_dir]\n",
    "content_names = [f for f in os.listdir(content_dir) if os.path.isfile(os.path.join(content_dir, f))]\n",
    "style_names = [f for f in os.listdir(style_dir) if os.path.isfile(os.path.join(style_dir, f))]\n",
    "print(content_names)\n",
    "print(style_names)\n",
    "opt_imgs=[]\n",
    "for cn in content_names:\n",
    "    for sn in style_names:\n",
    "        start = time()\n",
    "        img_names = [sn,cn]\n",
    "        imgs = [Image.open(img_dirs[i] + name) for i,name in enumerate(img_names)]\n",
    "        imgs_torch = [prep(img) for img in imgs]\n",
    "        if torch.cuda.is_available():\n",
    "            imgs_torch = [Variable(img.unsqueeze(0).cuda()) for img in imgs_torch]\n",
    "        else:\n",
    "            imgs_torch = [Variable(img.unsqueeze(0)) for img in imgs_torch]\n",
    "        style_image, content_image = imgs_torch\n",
    "\n",
    "        # opt_img = Variable(torch.randn(content_image.size()).type_as(content_image.data), requires_grad=True) #random init\n",
    "        opt_img = Variable(content_image.data.clone(), requires_grad=True)\n",
    "        for img in imgs:\n",
    "            plt.imshow(img);plt.show()\n",
    "        #define layers, loss functions, weights and compute optimization targets\n",
    "        style_layers = ['r11','r21','r31','r41', 'r51'] \n",
    "        content_layers = ['r42']\n",
    "        loss_layers = style_layers + content_layers\n",
    "        loss_fns = [GramMSELoss()] * len(style_layers) + [nn.MSELoss()] * len(content_layers)\n",
    "        if torch.cuda.is_available():\n",
    "            loss_fns = [loss_fn.cuda() for loss_fn in loss_fns]\n",
    "    \n",
    "        #these are good weights settings:\n",
    "        style_weights = [1e3/n**2 for n in [64,128,256,512,512]]\n",
    "        content_weights = [1e0]\n",
    "        weights = style_weights + content_weights\n",
    "        \n",
    "        #compute optimization targets\n",
    "        style_targets = [GramMatrix()(A).detach() for A in vgg(style_image, style_layers)]\n",
    "        content_targets = [A.detach() for A in vgg(content_image, content_layers)]\n",
    "        targets = style_targets + content_targets\n",
    "\n",
    "        lap_target = lap(content_image)\n",
    "\n",
    "        #run style transfer\n",
    "        max_iter = 2000\n",
    "        show_iter = 50\n",
    "        optimizer = optim.LBFGS([opt_img],lr=1)\n",
    "        optimizer = optimizer\n",
    "        n_iter=[0]\n",
    "\n",
    "        while n_iter[0] <= max_iter:\n",
    "            torch.cuda.empty_cache()\n",
    "            def closure():\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                out = vgg(opt_img, loss_layers)\n",
    "                layer_losses = [weights[a] * loss_fns[a](A, targets[a]) for a,A in enumerate(out)]\n",
    "                loss_lap = nn.MSELoss()(lap(opt_img),lap_target)\n",
    "                loss = torch.sum(torch.stack(layer_losses)) + loss_lap*100 \n",
    "                loss.backward()\n",
    "                n_iter[0]+=1\n",
    "                if n_iter[0]%show_iter == (show_iter-1):\n",
    "                    print('Iteration: %d, loss: %f'%(n_iter[0]+1, loss.item()))\n",
    "                return loss\n",
    "            optimizer.step(closure)\n",
    "            if n_iter[0] >= max_iter:\n",
    "                break\n",
    "        #display result\n",
    "        out_img = postp(opt_img.data[0].cpu().squeeze())\n",
    "        opt_imgs.append(opt_img)\n",
    "        plt.imshow(out_img)\n",
    "        plt.show()\n",
    "        plt.gcf().set_size_inches(10,10)\n",
    "        print('Time elapsed: %f'%(time()-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0f6e4043",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_img1 = [postp(opt_img1.data[0].cpu().squeeze())  for opt_img1 in opt_imgs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09aa5bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_img1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd00659",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_img1[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22590105",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_img1[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42bc580",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_img1[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c310dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_img1[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e71411",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_img1[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61fb4cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_img1[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb4e4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_img1[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2f678a",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_img1[8]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
